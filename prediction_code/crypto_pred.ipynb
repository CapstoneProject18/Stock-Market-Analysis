{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crypto_pred.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "QjQoScFhioFJ",
        "colab_type": "code",
        "outputId": "596163f1-2099-4a57-d202-33c9e8285670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d5cF1Kubj5dg",
        "colab_type": "code",
        "outputId": "c4495a3b-6cfa-46ca-e473-08c01b11a70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2228
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'01.12.15 AM.zip'\n",
            "'01.12.15 AM.zip (Unzipped Files)'\n",
            "'02.12.15 AM.zip'\n",
            "'02.12.15 AM.zip (Unzipped Files)'\n",
            "'02.12.15 AM.zip (Unzipped Files) (1)'\n",
            "'04.05.2017 AM.zip'\n",
            "'04.05.2017 AM.zip (Unzipped Files)'\n",
            "'04.05.2017 AM.zip (Unzipped Files) (1)'\n",
            "'04.12.15 AM.zip'\n",
            "'04.12.15 AM.zip (Unzipped Files)'\n",
            "'05.04.2016 AM.zip'\n",
            "'05.04.2016 AM.zip (Unzipped Files)'\n",
            " 07.09.zip\n",
            "'07.09.zip (Unzipped Files)'\n",
            "'07.12.15 AM.zip'\n",
            "'07.12.15 AM.zip (Unzipped Files)'\n",
            "'07.12.2016 AM.zip'\n",
            "'08.12.15 AM.zip'\n",
            "'08.12.15 AM.zip (Unzipped Files)'\n",
            "'08.12.15 AM.zip (Unzipped Files) (1)'\n",
            "'08.12.2016 AM.zip'\n",
            "'08.12.2016 AM.zip (Unzipped Files)'\n",
            "'08.12.2016 AM.zip (Unzipped Files) (1)'\n",
            "'09.04.2016 AM.zip'\n",
            "'09.04.2016 AM.zip (Unzipped Files)'\n",
            " 09.09.zip\n",
            "'09.09.zip (Unzipped Files)'\n",
            " 11.05.2016_.zip\n",
            "'11.05.2016_.zip (Unzipped Files)'\n",
            " 12.09.zip\n",
            "'12.09.zip (Unzipped Files)'\n",
            "'13.10.2015 PM.zip'\n",
            "'13.10.2015 PM.zip (Unzipped Files)'\n",
            "'14.10.2015 AM.zip'\n",
            "'14.10.2015 AM.zip (Unzipped Files)'\n",
            "'14.12.15 AM.zip'\n",
            "'14.12.15 AM.zip (Unzipped Files)'\n",
            "'14.12.15 AM.zip (Unzipped Files) (1)'\n",
            "'15.10.2015 AM.zip'\n",
            "'15.10.2015 AM.zip (Unzipped Files)'\n",
            "'15 Feb_PM-.zip'\n",
            "'15 Feb_PM-.zip (Unzipped Files)'\n",
            "'15 Feb_PM-.zip (Unzipped Files) (1)'\n",
            " 16.05.2016.zip\n",
            "'16.05.2016.zip (Unzipped Files)'\n",
            " 17.02.2016.zip\n",
            "'17.02.2016.zip (Unzipped Files)'\n",
            "'17.02.2016.zip (Unzipped Files) (1)'\n",
            "'17.02.2016.zip (Unzipped Files) (2)'\n",
            "'17.05.2017 AM.zip'\n",
            "'17.05.2017 AM.zip (Unzipped Files)'\n",
            "'17.05.2017 AM.zip (Unzipped Files) (1)'\n",
            "'17.05.2017 AM.zip (Unzipped Files) (2)'\n",
            " 17.09.zip\n",
            "'17.09.zip (Unzipped Files)'\n",
            "'17.10.2015 AM.ZIP'\n",
            "'17.10.2015 AM.ZIP (Unzipped Files)'\n",
            "'18.05.2016 (2).zip'\n",
            "'18.05.2016 (2).zip (Unzipped Files)'\n",
            " 18.09.zip\n",
            "'18.09.zip (Unzipped Files)'\n",
            " 18.2.2016.zip\n",
            "'18.2.2016.zip (Unzipped Files)'\n",
            " 20.02.2016.zip\n",
            "'20.02.2016.zip (Unzipped Files)'\n",
            "'21.5. 2018.zip'\n",
            "'21.5. 2018.zip (Unzipped Files)'\n",
            "'21.5. 2018.zip (Unzipped Files) (1)'\n",
            " 30.Oct.2017_AM.zip\n",
            "'30.Oct.2017_AM.zip (Unzipped Files)'\n",
            " Attendance.gsheet\n",
            "'B.Tech. Semester I 2015-16 Timetable.xlsx'\n",
            "'Colab Notebooks'\n",
            "'Cracking the Coding Interview, 6th Edition 189 Programming Questions and Solutions.pdf.zip (Unzipped Files)'\n",
            " crypto\n",
            " crypto_pred.ipynb\n",
            "'Daily Report.gsheet'\n",
            " database.sqlite\n",
            "'Directi Qualifying round QUESTIONS.zip'\n",
            " eg.zip\n",
            "'eg.zip (Unzipped Files)'\n",
            "'eg.zip (Unzipped Files) (1)'\n",
            " Face_1.ipynb\n",
            " FaceRec\n",
            " football-db.zip\n",
            " FootballDB.zip\n",
            "'Ganesh Singh - Software Requirement Specification.gdoc'\n",
            " garry_chess\n",
            "'GDB_Commands_Shivangi Tak_S5_U101115FCS213.zip'\n",
            "'Grade book.gsheet'\n",
            "'identify animal'\n",
            " IMG_20160428_233240_1.jpg\n",
            " IMG_20160428_233252_1.jpg\n",
            " IMG_20160428_233306_1.jpg\n",
            " IMG_20160428_233320_1.jpg\n",
            " IMG_20160428_233335_1.jpg\n",
            " IMG_20160428_233350_1.jpg\n",
            " IMG_20160428_233402_1.jpg\n",
            " IMG_20160428_233414_1.jpg\n",
            " IMG_20160428_233436_1.jpg\n",
            " IMG_20160428_233448_1.jpg\n",
            " IMG_20160428_233500_1.jpg\n",
            "'javaprograms (1).odt.gdoc'\n",
            " javaprograms.odt\n",
            " javaprograms.odt.gdoc\n",
            " mat_mul.ipynb\n",
            "'New folder.zip'\n",
            "'New folder.zip (Unzipped Files)'\n",
            "'New folder.zip (Unzipped Files) (1)'\n",
            "'New folder.zip (Unzipped Files) (2)'\n",
            "'NUPL 6 List of All Players.xlsx'\n",
            "'Open Cage Cricket .gsheet'\n",
            "'R&D Final Report.pdf'\n",
            "'R&D Project Final Report.pdf'\n",
            "'Sep.11(AM).zip'\n",
            "'Sep.11(AM).zip (Unzipped Files)'\n",
            "'Sep.12(AM).zip'\n",
            "'Sep.12(AM).zip (Unzipped Files)'\n",
            "'Sep.13(AM).zip'\n",
            "'Sep.13(AM).zip (Unzipped Files)'\n",
            "'Sep.13(AM).zip (Unzipped Files) (1)'\n",
            "'Sep.14(AM).zip'\n",
            "'Sep.14(AM).zip (Unzipped Files)'\n",
            " Software_Design.sdr\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n",
            " Untitled3.ipynb\n",
            "'Untitled Diagram.html'\n",
            "'Untitled form.gform'\n",
            " videos.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zovXXuGynzph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,LSTM,CuDNNLSTM,BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
        "#drive/My Drive/crypto/BCH-USD.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGZvwppyqvEs",
        "colab_type": "code",
        "outputId": "1275eff8-68b9-4af9-8d72-97fc099569e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"drive/My Drive/crypto/BCH-USD.csv\", names=[\"time\",\"low\",\n",
        "                                      \"high\",\"open\",\"close\",\"volume\"],index_col=False)\n",
        "print(df.head())\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         time         low        high        open       close     volume\n",
            "0  1528968660  871.650024  871.729980  871.650024  871.719971   5.675361\n",
            "1  1528968720  870.859985  871.719971  871.719971  870.859985  26.856577\n",
            "2  1528968780  870.099976  871.090027  871.090027  870.099976   1.124300\n",
            "3  1528968840  868.830017  870.950012  868.830017  870.789978   1.749862\n",
            "4  1528968900  870.000000  870.000000  870.000000  870.000000   1.680500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a8S7Ga9ERdFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEQ_LEN=60\n",
        "FUTURE_PERIOD_PREDICT=3\n",
        "RATIO_TO_PREDICT=\"LTC-USD\"\n",
        "EPOCHS=10\n",
        "BATCH_SIZE=64\n",
        "NAME=f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4GlWnSXFRhJR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify(current,future):\n",
        "    if float(future)>float(current):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8qA1_CpAaTeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_df(df):\n",
        "    df = df.drop(\"future\", 1)  # don't need this anymore.\n",
        "\n",
        "    for col in df.columns:  # go through all of the columns\n",
        "        if col != \"target\":  # normalize all ... except for the target itself!\n",
        "            df[col] = df[col].pct_change()  # pct change \"normalizes\" the different currencies (each crypto coin has vastly diff values, we're really more interested in the other coin's movements)\n",
        "            df.dropna(inplace=True)  # remove the nas created by pct_change\n",
        "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
        "\n",
        "    df.dropna(inplace=True) \n",
        "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
        "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
        "\n",
        "    for i in df.values:  # iterate over the values\n",
        "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
        "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
        "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
        "\n",
        "    random.shuffle(sequential_data)  \n",
        "    \n",
        "    buys=[]\n",
        "    sells=[]\n",
        "    \n",
        "    for seq,target in sequential_data:\n",
        "        if target==0:\n",
        "            sells.append([seq,target])\n",
        "        elif target==1:\n",
        "            buys.append([seq,target])\n",
        "            \n",
        "    random.shuffle(buys)\n",
        "    random.shuffle(sells)\n",
        "    \n",
        "    lower=min(len(buys), len(sells))\n",
        "    \n",
        "    buys=buys[:lower]\n",
        "    sells=sells[:lower]\n",
        "    \n",
        "    sequential_data=buys+sells\n",
        "    random.shuffle(sequential_data)\n",
        "    \n",
        "    X=[]\n",
        "    Y=[]\n",
        "    \n",
        "    for seq,target in sequential_data:\n",
        "        X.append(seq)\n",
        "        Y.append(target)\n",
        "        \n",
        "    return np.array(X),Y    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7uoskZ1rUM2",
        "colab_type": "code",
        "outputId": "794279dd-08d9-4f54-c46f-f2061adc3d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "cell_type": "code",
      "source": [
        "main_df=pd.DataFrame()\n",
        "ratios=[\"BTC-USD\",\"LTC-USD\",\"ETH-USD\",\"BCH-USD\"]\n",
        "for ratio in ratios:\n",
        "    dataset=f\"drive/My Drive/crypto/{ratio}.csv\"\n",
        "    df=pd.read_csv(dataset,names=[\"time\",\"low\", \"high\",\"open\",\"close\",\"volume\"],index_col=False)\n",
        "    \n",
        "    df.rename(columns={\"close\":f\"{ratio}_close\",\"volume\":f\"{ratio}_volume\"},inplace=True)\n",
        "    \n",
        "    df.set_index(\"time\",inplace=True)\n",
        "    df=df[[f\"{ratio}_close\",f\"{ratio}_volume\"]]\n",
        "    if len(main_df)==0:\n",
        "        main_df=df\n",
        "    else:\n",
        "        main_df=main_df.join(df)\n",
        "\n",
        "        \n",
        "main_df[\"future\"]=main_df[f\"{RATIO_TO_PREDICT}_close\"].shift\\\n",
        "                                               (-FUTURE_PERIOD_PREDICT)        \n",
        "\n",
        "main_df[\"target\"]=list(map(classify,main_df\\\n",
        "                    [f\"{RATIO_TO_PREDICT}_close\"],main_df[\"future\"]))\n",
        "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]].head(10)) \n",
        "\n",
        "times=sorted(main_df.index.values)\n",
        "#separating the test data\n",
        "last_5pct=times[-int(0.05*len(times))]\n",
        "validation_main_df=main_df[(main_df.index>=last_5pct)]\n",
        "#training data\n",
        "main_df=main_df[(main_df.index<last_5pct)]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            LTC-USD_close     future  target\n",
            "time                                        \n",
            "1528968660      96.580002  96.500000       0\n",
            "1528968720      96.660004  96.389999       0\n",
            "1528968780      96.570000  96.519997       0\n",
            "1528968840      96.500000  96.440002       0\n",
            "1528968900      96.389999  96.470001       1\n",
            "1528968960      96.519997  96.400002       0\n",
            "1528969020      96.440002  96.400002       0\n",
            "1528969080      96.470001  96.400002       0\n",
            "1528969140      96.400002  96.400002       0\n",
            "1528969200      96.400002  96.400002       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N9d4wck0uNYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0c770306-8895-45d6-f3a3-5a38c0efbe53"
      },
      "cell_type": "code",
      "source": [
        "train_x,train_y=preprocess_df(main_df)\n",
        "validation_x,validation_y=preprocess_df(validation_main_df)\n",
        "\n",
        "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
        "print(f\"Dont buys: {train_y.count(0),train_x.shape}, buys: {train_y.count(1)}\")\n",
        "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data: 69188 validation: 3062\n",
            "Dont buys: (34594, (69188, 60, 8)), buys: 34594\n",
            "VALIDATION Dont buys: 1531, buys: 1531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0pWwyXyjsnEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(CuDNNLSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
        "#(timesteps*data_dim )\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
        "\n",
        "model.add(CuDNNLSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(CuDNNLSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NC-cwVf-spfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1168
        },
        "outputId": "cf26126b-8e49-4b22-d278-fb7f68ac7ecf"
      },
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "filepath = \"/content/drive/My Drive/crypto/RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
        "checkpoint = ModelCheckpoint(\"{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_x, train_y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(validation_x, validation_y),\n",
        "    callbacks=[tensorboard, checkpoint],\n",
        ")\n",
        "\n",
        "# Score model\n",
        "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "# Save model\n",
        "model.save(\"models/{}\".format(NAME))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 69188 samples, validate on 3062 samples\n",
            "Epoch 1/10\n",
            "69188/69188 [==============================] - 79s 1ms/step - loss: 0.6799 - acc: 0.5670 - val_loss: 0.6822 - val_acc: 0.5630\n",
            "Epoch 2/10\n",
            "69188/69188 [==============================] - 75s 1ms/step - loss: 0.6775 - acc: 0.5724 - val_loss: 0.6800 - val_acc: 0.5748\n",
            "Epoch 3/10\n",
            "69188/69188 [==============================] - 74s 1ms/step - loss: 0.6744 - acc: 0.5793 - val_loss: 0.6824 - val_acc: 0.5686\n",
            "Epoch 4/10\n",
            "69188/69188 [==============================] - 77s 1ms/step - loss: 0.6692 - acc: 0.5890 - val_loss: 0.6847 - val_acc: 0.5555\n",
            "Epoch 5/10\n",
            "69188/69188 [==============================] - 76s 1ms/step - loss: 0.6641 - acc: 0.6003 - val_loss: 0.7045 - val_acc: 0.5382\n",
            "Epoch 6/10\n",
            "69188/69188 [==============================] - 77s 1ms/step - loss: 0.6555 - acc: 0.6115 - val_loss: 0.6948 - val_acc: 0.5578\n",
            "Epoch 7/10\n",
            "69188/69188 [==============================] - 74s 1ms/step - loss: 0.6435 - acc: 0.6266 - val_loss: 0.7152 - val_acc: 0.5385\n",
            "Epoch 8/10\n",
            "69188/69188 [==============================] - 75s 1ms/step - loss: 0.6295 - acc: 0.6445 - val_loss: 0.7132 - val_acc: 0.5611\n",
            "Epoch 9/10\n",
            "69188/69188 [==============================] - 72s 1ms/step - loss: 0.6156 - acc: 0.6573 - val_loss: 0.7610 - val_acc: 0.5281\n",
            "Epoch 10/10\n",
            "69188/69188 [==============================] - 75s 1ms/step - loss: 0.5993 - acc: 0.6763 - val_loss: 0.7732 - val_acc: 0.5242\n",
            "Test loss: 0.7731986477591491\n",
            "Test accuracy: 0.5241672110218849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bb0144125f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'models/60-SEQ-3-PRED-1543247229', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uM-Jtsp8OFB7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}