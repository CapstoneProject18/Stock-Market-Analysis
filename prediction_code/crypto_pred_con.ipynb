{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crypto_pred.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "QjQoScFhioFJ",
        "colab_type": "code",
        "outputId": "69163720-b07b-4784-deb8-005e5a66622f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d5cF1Kubj5dg",
        "colab_type": "code",
        "outputId": "1f4ce3e5-e7aa-4669-f50c-0ec00e80041f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2208
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'01.12.15 AM.zip'\n",
            "'01.12.15 AM.zip (Unzipped Files)'\n",
            "'02.12.15 AM.zip'\n",
            "'02.12.15 AM.zip (Unzipped Files)'\n",
            "'02.12.15 AM.zip (Unzipped Files) (1)'\n",
            "'04.05.2017 AM.zip'\n",
            "'04.05.2017 AM.zip (Unzipped Files)'\n",
            "'04.05.2017 AM.zip (Unzipped Files) (1)'\n",
            "'04.12.15 AM.zip'\n",
            "'04.12.15 AM.zip (Unzipped Files)'\n",
            "'05.04.2016 AM.zip'\n",
            "'05.04.2016 AM.zip (Unzipped Files)'\n",
            " 07.09.zip\n",
            "'07.09.zip (Unzipped Files)'\n",
            "'07.12.15 AM.zip'\n",
            "'07.12.15 AM.zip (Unzipped Files)'\n",
            "'07.12.2016 AM.zip'\n",
            "'08.12.15 AM.zip'\n",
            "'08.12.15 AM.zip (Unzipped Files)'\n",
            "'08.12.15 AM.zip (Unzipped Files) (1)'\n",
            "'08.12.2016 AM.zip'\n",
            "'08.12.2016 AM.zip (Unzipped Files)'\n",
            "'08.12.2016 AM.zip (Unzipped Files) (1)'\n",
            "'09.04.2016 AM.zip'\n",
            "'09.04.2016 AM.zip (Unzipped Files)'\n",
            " 09.09.zip\n",
            "'09.09.zip (Unzipped Files)'\n",
            " 11.05.2016_.zip\n",
            "'11.05.2016_.zip (Unzipped Files)'\n",
            " 12.09.zip\n",
            "'12.09.zip (Unzipped Files)'\n",
            "'13.10.2015 PM.zip'\n",
            "'13.10.2015 PM.zip (Unzipped Files)'\n",
            "'14.10.2015 AM.zip'\n",
            "'14.10.2015 AM.zip (Unzipped Files)'\n",
            "'14.12.15 AM.zip'\n",
            "'14.12.15 AM.zip (Unzipped Files)'\n",
            "'14.12.15 AM.zip (Unzipped Files) (1)'\n",
            "'15.10.2015 AM.zip'\n",
            "'15.10.2015 AM.zip (Unzipped Files)'\n",
            "'15 Feb_PM-.zip'\n",
            "'15 Feb_PM-.zip (Unzipped Files)'\n",
            "'15 Feb_PM-.zip (Unzipped Files) (1)'\n",
            " 16.05.2016.zip\n",
            "'16.05.2016.zip (Unzipped Files)'\n",
            " 17.02.2016.zip\n",
            "'17.02.2016.zip (Unzipped Files)'\n",
            "'17.02.2016.zip (Unzipped Files) (1)'\n",
            "'17.02.2016.zip (Unzipped Files) (2)'\n",
            "'17.05.2017 AM.zip'\n",
            "'17.05.2017 AM.zip (Unzipped Files)'\n",
            "'17.05.2017 AM.zip (Unzipped Files) (1)'\n",
            "'17.05.2017 AM.zip (Unzipped Files) (2)'\n",
            " 17.09.zip\n",
            "'17.09.zip (Unzipped Files)'\n",
            "'17.10.2015 AM.ZIP'\n",
            "'17.10.2015 AM.ZIP (Unzipped Files)'\n",
            "'18.05.2016 (2).zip'\n",
            "'18.05.2016 (2).zip (Unzipped Files)'\n",
            " 18.09.zip\n",
            "'18.09.zip (Unzipped Files)'\n",
            " 18.2.2016.zip\n",
            "'18.2.2016.zip (Unzipped Files)'\n",
            " 20.02.2016.zip\n",
            "'20.02.2016.zip (Unzipped Files)'\n",
            "'21.5. 2018.zip'\n",
            "'21.5. 2018.zip (Unzipped Files)'\n",
            "'21.5. 2018.zip (Unzipped Files) (1)'\n",
            " 30.Oct.2017_AM.zip\n",
            "'30.Oct.2017_AM.zip (Unzipped Files)'\n",
            " Attendance.gsheet\n",
            "'B.Tech. Semester I 2015-16 Timetable.xlsx'\n",
            "'Colab Notebooks'\n",
            "'Cracking the Coding Interview, 6th Edition 189 Programming Questions and Solutions.pdf.zip (Unzipped Files)'\n",
            " crypto\n",
            " crypto_pred.ipynb\n",
            "'Daily Report.gsheet'\n",
            " database.sqlite\n",
            "'Directi Qualifying round QUESTIONS.zip'\n",
            " eg.zip\n",
            "'eg.zip (Unzipped Files)'\n",
            "'eg.zip (Unzipped Files) (1)'\n",
            " Face_1.ipynb\n",
            " FaceRec\n",
            " football-db.zip\n",
            " FootballDB.zip\n",
            "'Ganesh Singh - Software Requirement Specification.gdoc'\n",
            " garry_chess\n",
            "'GDB_Commands_Shivangi Tak_S5_U101115FCS213.zip'\n",
            "'Grade book.gsheet'\n",
            "'identify animal'\n",
            " IMG_20160428_233240_1.jpg\n",
            " IMG_20160428_233252_1.jpg\n",
            " IMG_20160428_233306_1.jpg\n",
            " IMG_20160428_233320_1.jpg\n",
            " IMG_20160428_233335_1.jpg\n",
            " IMG_20160428_233350_1.jpg\n",
            " IMG_20160428_233402_1.jpg\n",
            " IMG_20160428_233414_1.jpg\n",
            " IMG_20160428_233436_1.jpg\n",
            " IMG_20160428_233448_1.jpg\n",
            " IMG_20160428_233500_1.jpg\n",
            "'javaprograms (1).odt.gdoc'\n",
            " javaprograms.odt\n",
            " javaprograms.odt.gdoc\n",
            " mat_mul.ipynb\n",
            "'New folder.zip'\n",
            "'New folder.zip (Unzipped Files)'\n",
            "'New folder.zip (Unzipped Files) (1)'\n",
            "'New folder.zip (Unzipped Files) (2)'\n",
            "'NUPL 6 List of All Players.xlsx'\n",
            "'Open Cage Cricket .gsheet'\n",
            "'R&D Final Report.pdf'\n",
            "'R&D Project Final Report.pdf'\n",
            "'Sep.11(AM).zip'\n",
            "'Sep.11(AM).zip (Unzipped Files)'\n",
            "'Sep.12(AM).zip'\n",
            "'Sep.12(AM).zip (Unzipped Files)'\n",
            "'Sep.13(AM).zip'\n",
            "'Sep.13(AM).zip (Unzipped Files)'\n",
            "'Sep.13(AM).zip (Unzipped Files) (1)'\n",
            "'Sep.14(AM).zip'\n",
            "'Sep.14(AM).zip (Unzipped Files)'\n",
            " Software_Design.sdr\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n",
            " Untitled3.ipynb\n",
            "'Untitled Diagram.html'\n",
            "'Untitled form.gform'\n",
            " videos.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zovXXuGynzph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense,Dropout,LSTM,CuDNNLSTM,BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "#drive/My Drive/crypto/BCH-USD.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGZvwppyqvEs",
        "colab_type": "code",
        "outputId": "369a7b5f-e20a-4a86-997f-5457b0876a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"drive/My Drive/crypto/BCH-USD.csv\", names=[\"time\",\"low\",\n",
        "                                      \"high\",\"open\",\"close\",\"volume\"],index_col=False)\n",
        "print(df.head())\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         time         low        high        open       close     volume\n",
            "0  1528968660  871.650024  871.729980  871.650024  871.719971   5.675361\n",
            "1  1528968720  870.859985  871.719971  871.719971  870.859985  26.856577\n",
            "2  1528968780  870.099976  871.090027  871.090027  870.099976   1.124300\n",
            "3  1528968840  868.830017  870.950012  868.830017  870.789978   1.749862\n",
            "4  1528968900  870.000000  870.000000  870.000000  870.000000   1.680500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a8S7Ga9ERdFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEQ_LEN=60\n",
        "FUTURE_PERIOD_PREDICT=3\n",
        "RATIO_TO_PREDICT=\"LTC-USD\"\n",
        "EPOCHS=10\n",
        "BATCH_SIZE=64\n",
        "NAME=f\"{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4GlWnSXFRhJR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify(current,future):\n",
        "    if float(future)>float(current):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8qA1_CpAaTeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_df(df):\n",
        "    df = df.drop(\"future\", 1)  \n",
        "\n",
        "    for col in df.columns:  \n",
        "        if col != \"target\":  \n",
        "            df[col] = df[col].pct_change()  \n",
        "            df.dropna(inplace=True) \n",
        "            df[col] = preprocessing.scale(df[col].values)  \n",
        "\n",
        "    df.dropna(inplace=True) \n",
        "    sequential_data = []  \n",
        "    prev_days = deque(maxlen=SEQ_LEN) \n",
        "\n",
        "    for i in df.values: \n",
        "        prev_days.append([n for n in i[:-1]]) \n",
        "        if len(prev_days) == SEQ_LEN:  \n",
        "            sequential_data.append([np.array(prev_days), i[-1]])  \n",
        "\n",
        "    random.shuffle(sequential_data)  \n",
        "    \n",
        "    buys=[]\n",
        "    sells=[]\n",
        "    \n",
        "    for seq,target in sequential_data:\n",
        "        if target==0:\n",
        "            sells.append([seq,target])\n",
        "        elif target==1:\n",
        "            buys.append([seq,target])\n",
        "            \n",
        "    random.shuffle(buys)\n",
        "    random.shuffle(sells)\n",
        "    \n",
        "    lower=min(len(buys), len(sells))\n",
        "    \n",
        "    buys=buys[:lower]\n",
        "    sells=sells[:lower]\n",
        "    \n",
        "    sequential_data=buys+sells\n",
        "    random.shuffle(sequential_data)\n",
        "    \n",
        "    X=[]\n",
        "    Y=[]\n",
        "    \n",
        "    for seq,target in sequential_data:\n",
        "        X.append(seq)\n",
        "        Y.append(target)\n",
        "        \n",
        "    return np.array(X),Y    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7uoskZ1rUM2",
        "colab_type": "code",
        "outputId": "2630aa36-0964-4ef2-b60b-f09f38726984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "cell_type": "code",
      "source": [
        "main_df=pd.DataFrame()\n",
        "ratios=[\"BTC-USD\",\"LTC-USD\",\"ETH-USD\",\"BCH-USD\"]\n",
        "for ratio in ratios:\n",
        "    dataset=f\"drive/My Drive/crypto/{ratio}.csv\"\n",
        "    df=pd.read_csv(dataset,names=[\"time\",\"low\", \"high\",\"open\",\"close\",\"volume\"],index_col=False)\n",
        "    \n",
        "    df.rename(columns={\"close\":f\"{ratio}_close\",\"volume\":f\"{ratio}_volume\"},inplace=True)\n",
        "    \n",
        "    df.set_index(\"time\",inplace=True)\n",
        "    df=df[[f\"{ratio}_close\",f\"{ratio}_volume\"]]\n",
        "    if len(main_df)==0:\n",
        "        main_df=df\n",
        "    else:\n",
        "        main_df=main_df.join(df)\n",
        "\n",
        "        \n",
        "main_df[\"future\"]=main_df[f\"{RATIO_TO_PREDICT}_close\"].shift\\\n",
        "                                               (-FUTURE_PERIOD_PREDICT)        \n",
        "\n",
        "main_df[\"target\"]=list(map(classify,main_df\\\n",
        "                    [f\"{RATIO_TO_PREDICT}_close\"],main_df[\"future\"]))\n",
        "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]].head(10)) \n",
        "\n",
        "times=sorted(main_df.index.values)\n",
        "#separating the test data\n",
        "last_5pct=times[-int(0.05*len(times))]\n",
        "validation_main_df=main_df[(main_df.index>=last_5pct)]\n",
        "#training data\n",
        "main_df=main_df[(main_df.index<last_5pct)]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            LTC-USD_close     future  target\n",
            "time                                        \n",
            "1528968660      96.580002  96.500000       0\n",
            "1528968720      96.660004  96.389999       0\n",
            "1528968780      96.570000  96.519997       0\n",
            "1528968840      96.500000  96.440002       0\n",
            "1528968900      96.389999  96.470001       1\n",
            "1528968960      96.519997  96.400002       0\n",
            "1528969020      96.440002  96.400002       0\n",
            "1528969080      96.470001  96.400002       0\n",
            "1528969140      96.400002  96.400002       0\n",
            "1528969200      96.400002  96.400002       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N9d4wck0uNYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6e7980f6-ea50-4401-d0e2-1d6a7b08fdf3"
      },
      "cell_type": "code",
      "source": [
        "train_x,train_y=preprocess_df(main_df)\n",
        "validation_x,validation_y=preprocess_df(validation_main_df)\n",
        "\n",
        "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
        "print(f\"Dont buys: {train_y.count(0),train_x.shape}, buys: {train_y.count(1)}\")\n",
        "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data: 69188 validation: 3062\n",
            "Dont buys: (34594, (69188, 60, 8)), buys: 34594\n",
            "VALIDATION Dont buys: 1531, buys: 1531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0pWwyXyjsnEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(CuDNNLSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
        "#(timesteps*data_dim )\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())  #normalizes activation outputs\n",
        "\n",
        "model.add(CuDNNLSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(CuDNNLSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NC-cwVf-spfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "747fe339-315a-424b-ec12-b80a6f4cc151"
      },
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "filepath = \"/content/drive/My Drive/crypto/RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
        "checkpoint = ModelCheckpoint(\"{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_x, train_y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(validation_x, validation_y),\n",
        "    callbacks=[tensorboard, checkpoint],\n",
        ")\n",
        "\n",
        "# Score model\n",
        "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "# Save model\n",
        "model.save(\"/content/drive/My Drive/crypto/{}\".format(NAME))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 69188 samples, validate on 3062 samples\n",
            "Epoch 1/10\n",
            "69188/69188 [==============================] - 75s 1ms/step - loss: 0.6548 - acc: 0.6123 - val_loss: 0.6944 - val_acc: 0.5496\n",
            "Epoch 2/10\n",
            "69188/69188 [==============================] - 67s 975us/step - loss: 0.6470 - acc: 0.6214 - val_loss: 0.7040 - val_acc: 0.5519\n",
            "Epoch 3/10\n",
            "69188/69188 [==============================] - 68s 986us/step - loss: 0.6362 - acc: 0.6331 - val_loss: 0.7029 - val_acc: 0.5604\n",
            "Epoch 4/10\n",
            "69188/69188 [==============================] - 66s 950us/step - loss: 0.6227 - acc: 0.6481 - val_loss: 0.7301 - val_acc: 0.5460\n",
            "Epoch 5/10\n",
            "69188/69188 [==============================] - 68s 988us/step - loss: 0.6083 - acc: 0.6642 - val_loss: 0.7575 - val_acc: 0.5457\n",
            "Epoch 6/10\n",
            "69188/69188 [==============================] - 67s 965us/step - loss: 0.5939 - acc: 0.6789 - val_loss: 0.7544 - val_acc: 0.5480\n",
            "Epoch 7/10\n",
            "69188/69188 [==============================] - 67s 971us/step - loss: 0.5757 - acc: 0.6949 - val_loss: 0.7617 - val_acc: 0.5509\n",
            "Epoch 8/10\n",
            "69188/69188 [==============================] - 66s 959us/step - loss: 0.5642 - acc: 0.7045 - val_loss: 0.7883 - val_acc: 0.5428\n",
            "Epoch 9/10\n",
            "69188/69188 [==============================] - 69s 999us/step - loss: 0.5473 - acc: 0.7166 - val_loss: 0.8138 - val_acc: 0.5464\n",
            "Epoch 10/10\n",
            "69188/69188 [==============================] - 68s 986us/step - loss: 0.5351 - acc: 0.7269 - val_loss: 0.8269 - val_acc: 0.5568\n",
            "Test loss: 0.8269301214146505\n",
            "Test accuracy: 0.5568256041802744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uM-Jtsp8OFB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b8f0c75f-bde4-47fa-d543-abfc78073333"
      },
      "cell_type": "code",
      "source": [
        "my_model=load_model('drive/My Drive/crypto/RNN_Final-02-0.575.model')\n",
        "score = my_model.evaluate(validation_x, validation_y, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.6795209110912196\n",
            "Test accuracy: 0.5721750489097261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "81oRlA0_n5vs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2ae91ca5-743e-41d0-9667-dacb0161a1fc"
      },
      "cell_type": "code",
      "source": [
        "pred=my_model.predict(validation_x)\n",
        "crrct=0\n",
        "x=[]\n",
        "res=[]\n",
        "for i in range(len(pred)):\n",
        "    if pred[i][0]>=pred[i][1]:\n",
        "        temp=0\n",
        "    else:\n",
        "        temp=1\n",
        "    \n",
        "    res.append(temp)\n",
        "    x.append(i)\n",
        "    if temp==validation_y[i]:\n",
        "        crrct=crrct+1\n",
        "        \n",
        "print((crrct/len(pred))*100)        \n",
        "#print(validation_y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57.21750489875899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zvVPXZ8TpNYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "895fafe2-01b0-41e3-98bc-edf5aa357285"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y_actu = pd.Series(validation_y, name='Actual')\n",
        "y_pred = pd.Series(res, name='Predicted')\n",
        "df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
        "print(df_confusion)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted     0     1   All\n",
            "Actual                     \n",
            "0.0         671   860  1531\n",
            "1.0         450  1081  1531\n",
            "All        1121  1941  3062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hKST_no0wdlU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}